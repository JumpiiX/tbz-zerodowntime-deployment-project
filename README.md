# Zero-Downtime Deployment eines Rust-basierten Blockchain-Indexers

<p align="center">
  <img src="docs/images/penumbra_logo.png" alt="Penumbra Logo">
</p>

Dieses Projekt implementiert ein Zero-Downtime Deployment-System f√ºr  Penumbra Blockchain Explorer, der kryptographische Blockchain-Daten f√ºr Endbenutzer verst√§ndlich visualisiert. [Penumbra](https://penumbra.zone/) ist eine datenschutzorientierte Zero-Knowledge-Blockchain, deren komplexe Datenstrukturen ohne spezielle Indexierung und Aufbereitung f√ºr normale Anwender nicht lesbar w√§ren.


## Wichtige Links

| Beschreibung | Link |
|--------------|------|
| **Doku-Repository** | [tbz-zerodowntime-deployment-project](https://github.com/JumpiiX/tbz-zerodowntime-deployment-project) |
| **Rust Blockchain Indexer** | [penumbra-explorer-backend](https://github.com/pk-labs/penumbra-explorer-backend) |
| **Scrum Board** | [GitHub Projects Board](https://github.com/users/JumpiiX/projects/2/views/1) |
| **Roadmap** | [Projekt Roadmap](https://github.com/users/JumpiiX/projects/2/views/4) |
| **Sprints** | [Milestones √úbersicht](https://github.com/JumpiiX/tbz-zerodowntime-deployment-project/milestones) |

## Inhaltsverzeichnis

1. [Einf√ºhrung und Problemstellung](#einf√ºhrung-und-problemstellung)
2. [Projektziele](#projektziele)
3. [Projektmanagement](#projektmanagement)
4. [Sprints und Fortschritt](#sprints-und-fortschritt)
5. [Technische Dokumentation](#technische-dokumentation)
6. [Risiken](#risiken)

## Einf√ºhrung und Problemstellung

### Problemstellung

Blockchain-Daten m√ºssen kontinuierlich und zuverl√§ssig indiziert werden, um sie in Echtzeit f√ºr Endanwender bereitzustellen ‚Äì beispielsweise in einem Block Explorer. Da sich das Datenmodell oder die Indizierungslogik regelm√§ssig √§ndert, m√ºssen bestehende Indexer-Instanzen ersetzt und Daten neu aufgebaut werden (Reindexing).

Ohne geeignete Strategie f√ºhrt dies zu:
- **Downtime** f√ºr Endnutzer
- **Inkonsistenten Daten** w√§hrend der Umschaltung
- **Benutzerfehlern** durch unvollst√§ndige Daten

### F√ºr wen l√∂sen wir das Problem?

Mein aktueller Arbeitgeber [PK Labs](https://www.pklabs.me/) ben√∂tigt eine L√∂sung, um unsere Rust-basierten Blockchain-Indexer f√ºr die Penumbra-Blockchain ohne Unterbrechungen aktualisieren zu k√∂nnen. Dies betrifft sowohl:
- Interne Entwicklungsteams, die kontinuierlichen Zugriff auf Blockchain-Daten ben√∂tigen
- Externe Kunden und Nutzer, die auf die API des Indexers f√ºr ihre Anwendungen angewiesen sind
- Unseren [Penumbra Blockchain Explorer](https://explorer.penumbra.zone/) 

### Herausforderungen bei aktuellen Deployments

Die bestehenden Deployment-Prozesse bei PK Labs haben folgende Herausforderungen:

| Herausforderung | Auswirkung | H√§ufigkeit |
|-----------------|------------|------------|
| Downtime w√§hrend Updates | Nutzer k√∂nnen nicht auf den Explorer zugreifen | Bei jedem Update (ca. 2x pro Woche) |
| Inkonsistente Daten | Falsche oder unvollst√§ndige Informationen werden angezeigt | Bei jedem Reindexing-Vorgang |
| Manuelle √úberwachung | Entwickler m√ºssen den Synchronisationsprozess √ºberwachen | Dauerhaft w√§hrend Updates |
| Kein automatischer Rollback | Bei Fehlern ist manuelles Eingreifen erforderlich | Bei ca. 15% der Deployments |

### L√∂sungsansatz: Blue-Green Deployment

Die L√∂sung f√ºr die genannten Herausforderungen ist ein **Blue-Green Deployment**-Konzept:

1. **Parallel-Betrieb:** Eine neue Indexer-Instanz (Green) wird parallel zur laufenden Instanz (Blue) gestartet
2. **Hintergrund-Synchronisation:** Die neue Instanz synchronisiert die Blockchain-Daten, w√§hrend die alte weiter im Produktivbetrieb ist
3. **Automatische Erkennung:** Ein Monitoring-System erkennt, wann die neue Instanz vollst√§ndig synchronisiert ist
4. **Nahtlose Umschaltung:** Ein NGINX Reverse Proxy leitet den Traffic ohne Unterbrechung zur neuen Instanz um
5. **Fallback-Option:** Bei Problemen kann sofort zur alten Instanz zur√ºckgeschaltet werden

#### Komponenten der L√∂sung

| Komponente | Zweck | Technologie |
|------------|-------|-------------|
| **NGINX Reverse Proxy** | Traffic-Steuerung zwischen Umgebungen | NGINX mit dynamischer Konfiguration |
| **Docker Container** | Isolierte Umgebungen f√ºr den Indexer | Docker, Docker Compose |
| **Monitoring-Script** | √úberwachung des Synchronisationsstatus | Shell-Script mit Docker-Abfragen |
| **Switch-Mechanismus** | Automatisierte Umschaltung | Shell-Script zur NGINX-Konfiguration |
| **Rollback-Mechanismus** | Sichere R√ºckkehr zur vorherigen Version | Automatisiertes Script mit Datenbank-Checks |

#### Visualisierung

![Zero-Downtime Deployment Flow](docs/diagrams/deployment_flow.PNG)
*Abbildung: Visualisierung des Zero-Downtime Deployment-Prozesses mit Blue-Green Strategie vom Code-Push bis zum Traffic-Switch*

### Projektvisualisierungen

#### SEUSAG-Diagramm

```mermaid
graph LR
    %% Externe Elemente
    DEV[üë§ Entwickler]
    USER[üë• Endnutzer]
    GIT[üì¶ GitHub]
    
    %% Systemgrenze
    subgraph "üîí Zero-Downtime Deployment System"
        %% Eingabe
        subgraph "üì• EINGABE"
            E1[Code Changes]
            E2[Konfiguration]
        end
        
        %% Steuerung
        subgraph "üéõÔ∏è STEUERUNG"
            S1[GitHub Actions]
            S2[NGINX Controller]
            S3[Health Monitor]
        end
        
        %% Umwandlung
        subgraph "‚öôÔ∏è UMWANDLUNG"
            U1[Build & Test]
            U2[Deploy Container]
            U3[Switch Traffic]
        end
        
        %% Ausgabe
        subgraph "üì§ AUSGABE"
            A1[API Service]
            A2[Status Reports]
        end
    end
    
    %% Hauptverbindungen (nur die wichtigsten!)
    DEV --> E1
    GIT --> E2
    
    E1 --> U1
    E2 --> U2
    
    S1 --> U1
    S2 --> U3
    S3 --> U3
    
    U1 --> U2
    U2 --> U3
    U3 --> A1
    
    A1 --> USER
    A2 --> DEV
    
    %% Feedback
    A2 -.-> S3
    
    %% Styling
    style DEV fill:#f9f9f9
    style USER fill:#f9f9f9
    style GIT fill:#f9f9f9
    
    style E1 fill:#e8f5e9
    style E2 fill:#e8f5e9
    
    style S1 fill:#ffebee
    style S2 fill:#ffebee
    style S3 fill:#ffebee
    
    style U1 fill:#e3f2fd
    style U2 fill:#e3f2fd
    style U3 fill:#e3f2fd
    
    style A1 fill:#fff3e0
    style A2 fill:#fff3e0
```
## Projektziele

Die Ziele dieses Projekts sind nach dem SMART-Prinzip definiert:

### 1. Eliminierung von Deployment-bedingten Downtimes
- **Spezifisch:** Implementierung eines Blue-Green Deployment-Systems, das Updates ohne Ausfallzeit erm√∂glicht
- **Messbar:** Reduzierung der Downtime von derzeit durchschnittlich 15 Minuten pro Deployment auf 0 Sekunden
- **Attraktiv:** Erh√∂hte Verf√ºgbarkeit des Blockchain-Explorers (Ziel: 99,9%)
- **Realistisch:** Umsetzbar mit NGINX, Docker und automatisierten Scripts
- **Terminiert:** Vollst√§ndig implementiert bis 09.07.2025

### 2. Automatisierung der Deployment-Pipeline
- **Spezifisch:** Entwicklung einer vollautomatischen Deployment-Pipeline vom Code bis zur Produktion
- **Messbar:** Reduzierung des manuellen Aufwands pro Deployment von 45 auf unter 5 Minuten
- **Attraktiv:** Geringere Fehleranf√§lligkeit und h√∂here Entwicklereffizienz
- **Realistisch:** Umsetzbar mit Shell-Scripts und Docker Compose
- **Terminiert:** Fertigstellung bis Ende Sprint 2 (02.06.2025)

### 3. Implementierung einer zuverl√§ssigen Synchronisationserkennung
- **Spezifisch:** Entwicklung eines Monitoring-Systems zur Erkennung des Indexer-Synchronisationsstatus
- **Messbar:** 100% zuverl√§ssige Erkennung mit einer Fehlertoleranz von maximal 0,1%
- **Attraktiv:** Vermeidung von Dateninkonsistenzen und falschen Umschaltungen
- **Realistisch:** Implementierbar mit API-Abfragen und intelligenten Vergleichsalgorithmen
- **Terminiert:** Abschluss bis Mitte Sprint 3 (15.06.2025)

## Projektmanagement

### Agile Arbeitsweise mit Scrum

F√ºr dieses Projekt wird **Scrum** als agile Methodik verwendet aus folgenden Gr√ºnden:

1. **Iterative Entwicklung:** Die komplexe Natur des Blue-Green Deployments erfordert einen schrittweisen Ansatz, bei dem Komponenten einzeln entwickelt und getestet werden k√∂nnen.

2. **Regelm√§ssiges Feedback:** Durch Sprint Reviews mit den Dozenten kann fr√ºhzeitig wertvolles Feedback eingeholt und in die weitere Entwicklung einbezogen werden.

3. **Transparente Fortschrittsverfolgung:** Das Scrum-Board bietet jederzeit einen klaren √úberblick √ºber den aktuellen Projektstand und offene Tasks.

4. **Flexibilit√§t:** Neue Erkenntnisse oder sich √§ndernde Anforderungen k√∂nnen schnell in die Projektplanung integriert werden.

#### Anpassungen f√ºr Einzelprojekt

Da es sich um ein Einzelprojekt handelt, wurden folgende Anpassungen am klassischen Scrum-Prozess vorgenommen:

| Scrum-Element | Klassische Umsetzung | Anpassung f√ºr Einzelprojekt |
|---------------|----------------------|----------------------------|
| **Daily Standup** | T√§gliches Team-Meeting | T√§gliche Selbstreflexion und Fortschrittsdokumentation |
| **Sprint Planning** | Team-Entscheidung | Abstimmung mit Dozenten und eigenst√§ndige Planung |
| **Peer Reviews** | Team-interne Reviews | Dozentenfeedback und Selbstreview anhand von Checklisten |
| **Product Owner** | Dedizierte Rolle | Rolle wird durch Dozenten und selbst √ºbernommen |
| **Scrum Master** | Dedizierte Rolle | Selbstorganisation mit regelm√§ssiger Prozessreflexion |

### Definition of Done

Ein Task gilt als abgeschlossen, wenn:

1. Die Implementierung vollst√§ndig ist und alle Akzeptanzkriterien erf√ºllt sind
2. Eine umfassende Dokumentation erstellt wurde
3. Tests durchgef√ºhrt und dokumentiert wurden (mit Testprotokoll)
4. Der Code/die √Ñnderung ist ins Repository eingecheckt

## Sprints und Fortschritt

### Sprint 1: Projektsetup und Grundlagen (14.04 - 09.05)

#### Sprint 1 Planung

Die Planung f√ºr Sprint 1 wurde am 14.04.2025 durchgef√ºhrt und folgende Ziele und Tasks wurden definiert:

**Sprint-Ziel:** Einrichtung der Projektgrundlagen und Dokumentation der Ausgangslage f√ºr das Zero-Downtime Deployment-System.


Die Planung wurde mit Corrado und Boris (Projektexperte) abgestimmt, und am 17.04.2025 erhielt ich das endg√ºltige "Go" f√ºr mein Projekt.

#### Sprint 1 Durchf√ºhrung und Ergebnisse

W√§hrend Sprint 1 wurden folgende Ergebnisse erzielt:

- **GitHub Repository** eingerichtet mit grundlegender Dokumentationsstruktur
- **GitHub Projects Board** als Scrum-Board konfiguriert mit User Stories und Akzeptanzkriterien
- **Ausf√ºhrliche Dokumentation** der Problemstellung, des L√∂sungsansatzes und der SMART-Ziele im README
- **Klare Begr√ºndung** f√ºr die Wahl von Scrum als agile Methodik und notwendige Anpassungen dokumentiert
- **Visualisierung** des Zero-Downtime Deployment-Prozesses mittels Diagramm
- **Definition of Done** etabliert und dokumentiert
- **Sprint 2 Planung** mit konkreten Tasks vorbereitet

#### Sprint 1 Review (09.05.2025)

Der Sprint 1 Review wurde am 09.05.2025 mit Corrado Parisi durchgef√ºhrt:

**Agenda:**
1. Projektstand
2. Erledigte Tasks
3. Herausforderungen 
4. Demo: Repository & Diagramm
5. Sprint 2 Planung
6. Fragen & Feedback

**Pr√§sentierte Ergebnisse:**
- Vollst√§ndiges README mit Problemstellung, L√∂sungsansatz und SMART-Zielen
- GitHub Repository mit Strukturierung und Dokumentation
- GitHub Projects Board mit User Stories und Akzeptanzkriterien

**Feedback:**
- Corrado Parisi hob die Wahl eines anspruchsvollen Projekts positiv hervor
- Er lobte die gut definierten Akzeptanzkriterien und die Qualit√§t der SMART-Ziele

**Vereinbarte Anpassungen:**
- Erstellung eines Gantt-Charts f√ºr die Projektplanung
- Entwicklung eines SEUSAG-Diagramms zur Visualisierung der Systemkomponenten
- Standardisierung des User Story-Formats nach dem Schema "Als [Rolle] m√∂chte ich [Funktionalit√§t], damit [Nutzen]"

**Reflexion:**
Die Dokumentation der Problemstellung und des L√∂sungsansatzes war erfolgreich. Die User Stories mit ihren detaillierten Akzeptanzkriterien wurden besonders positiv bewertet. Die Entwicklung eines klaren Deployment-Flow-Diagramms nahm mehr Zeit in Anspruch als geplant, wurde aber mit gutem Ergebnis abgeschlossen. Die Anpassung von Scrum f√ºr ein Einzelprojekt stellte eine Herausforderung dar, wurde aber durch die dokumentierten Anpassungen gut gel√∂st.

### Sprint 2: Server-Infrastruktur (10.05 - 02.06)

#### Sprint 2 Planung

Nach dem erfolgreichen Sprint 1 Review war ich richtig motiviert, endlich mit der technischen Umsetzung zu beginnen. Corrado hatte mir wertvolles Feedback gegeben, und jetzt ging es darum, die Theorie in die Praxis umzusetzen.

**Sprint-Ziel:** Eine funktionierende Production-Umgebung aufbauen, in der unser Penumbra Blockchain Indexer zuverl√§ssig l√§uft - mit automatischem Deployment und allem Drum und Dran.

**Was ich mir f√ºr Sprint 2 vorgenommen hatte:**

##### 1. Ubuntu Server Setup (3 Story Points)
- **Als** Software Engineer **m√∂chte ich** einen Ubuntu-Server in der Hetzner Cloud einrichten, **damit** ich eine stabile und leistungsf√§hige Umgebung f√ºr den Blockchain-Indexer bereitstellen kann.
- *Das war der erste wichtige Schritt - ohne Server l√§uft nichts!*

##### 2. Docker Installation (2 Story Points)
- **Als** Software Engineer **m√∂chte ich** Docker und Docker Compose auf dem Server installieren und konfigurieren, **damit** ich containerisierte Anwendungen f√ºr den Blockchain-Indexer bereitstellen kann.
- *Docker macht das Leben so viel einfacher...*

##### 3. NGINX Reverse Proxy (5 Story Points)
- **Als** Software Engineer **m√∂chte ich** NGINX als Reverse Proxy einrichten, **damit** ich eine zentrale Stelle f√ºr die Verkehrsweiterleitung zum Docker Container habe.
- *Der Klassiker f√ºr Production-Setups!*

##### 4. TLS/SSL Implementierung (3 Story Points)
- **Als** Software Engineer **m√∂chte ich** TLS/SSL mit Let's Encrypt implementieren, **damit** die Kommunikation zwischen Clients und dem Backend-Service verschl√ºsselt und sicher ist.
- *Sicherheit first - niemand will unverschl√ºsselte APIs!*

##### 5. CI/CD Pipeline (5 Story Points)
- **Als** Software Engineer **m√∂chte ich** einen GitHub Workflow f√ºr Continuous Integration und Deployment einrichten, **damit** Code-√Ñnderungen automatisch getestet, gebaut und auf dem Server bereitgestellt werden.
- *Automatisierung ist der Schl√ºssel zu meiner Sanity...*

##### 6. Dokumentation (3 Story Points)
- **Als** Software Engineer **m√∂chte ich** die Server-Infrastruktur und alle Konfigurationen umfassend dokumentieren, **damit** die Umgebung leicht nachvollziehbar, wartbar und bei Bedarf reproduzierbar ist.
- *Future-Me wird mir danken!*

**Geplante Velocity:** 21 Story Points - sportlich, aber machbar!

---

#### Sprint 2 - So lief es wirklich

##### üñ•Ô∏è Ubuntu Server Setup - Der Anfang von allem
**Status:** ‚úÖ Done!

Ich hab mir einen schicken Hetzner Cloud Server geklickt - Ubuntu 24.04 LTS, weil ich auf Nummer sicher gehen wollte. Die Specs:

```bash
# Mein neues Zuhause f√ºr den Indexer
OS: Ubuntu 24.04 LTS (die gute alte LTS!)
CPU: 2 vCPU (sollte reichen)
RAM: 4 GB (Rust ist ja memory-efficient)
Storage: 40 GB NVMe SSD (schnell muss es sein)
Location: N√ºrnberg (f√ºr die niedrige Latenz)
```

Das Setup war straightforward, aber ich hab nat√ºrlich direkt die Firewall vergessen und mich fast ausgesperrt. Zum Gl√ºck hatte ich noch eine Console-Session offen!

**Was ich gemacht hab:**

```bash
# SSH-Key kopieren (sicherer als Passw√∂rter!)
ssh-copy-id -i ~/.ssh/id_rsa.pub root@server-ip

# System updaten
apt update && apt upgrade -y

# Basis-Packages installieren
apt install -y curl wget git build-essential htop vim

# Firewall einrichten (diesmal richtig!)
ufw allow 22/tcp    # SSH
ufw allow 80/tcp    # HTTP
ufw allow 443/tcp   # HTTPS
ufw enable

# Zeitzone setzen
timedatectl set-timezone Europe/Zurich
```

**Learning:** Immer erst die Firewall-Regeln testen, BEVOR man sie aktiviert...

![Server Setup Complete](docs/images/server_setup_terminal.png)
*Terminal-Screenshot nach erfolgreichem Setup*

---

##### üê≥ Docker - Container sind Leben
**Status:** ‚úÖ Geschafft!

Docker Installation war ein Kinderspiel - die Docs von Docker sind echt gut. Hab die neueste Version installiert und direkt ein eigenes Netzwerk f√ºr unseren Indexer erstellt:

```bash
# Docker GPG Key hinzuf√ºgen
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Docker Repository hinzuf√ºgen
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Docker installieren
apt update
apt install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# Das Netzwerk f√ºr unseren Penumbra Explorer
docker network create penumbra-prod-net

# Deploy-User einrichten (Security first!)
sudo useradd -m -s /bin/bash deploy-penumbra-explorer
sudo usermod -aG docker deploy-penumbra-explorer
```

Der Deploy-User war wichtig - ich wollte nicht, dass GitHub Actions als root l√§uft. Das w√§re echt keine gute Idee gewesen.

**Test-Moment:** 
```bash
docker run hello-world
```
Das befriedigendste "Hello from Docker!" ever! üéâ

---

##### üîÄ NGINX - Der Traffic-Dirigent
**Status:** ‚úÖ L√§uft wie geschmiert!

NGINX einzurichten war... interessant. Ich hab bestimmt drei Mal die Konfiguration verkackt, bis ich gemerkt hab, dass ich den symbolischen Link vergessen hatte. Classic!

```bash
# NGINX installieren
apt install -y nginx

# Konfiguration erstellen
vim /etc/nginx/sites-available/penumbra-explorer
```

```nginx
# /etc/nginx/sites-available/penumbra-explorer
server {
    listen 80;
    server_name explorer.example.com;  # Keine echte Domain hier ;)
    
    # Hauptroute zum Indexer
    location / {
        proxy_pass http://localhost:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket support - wichtig f√ºr Live-Updates!
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        
        # Timeouts f√ºr lange Blockchain-Queries
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
    }
    
    # Health-Check Endpoint
    location /health {
        proxy_pass http://localhost:8080/health;
        access_log off;  # Spam vermeiden
    }
}
```

```bash
# Konfiguration aktivieren
ln -s /etc/nginx/sites-available/penumbra-explorer /etc/nginx/sites-enabled/

# Config testen (Life saver!)
nginx -t

# NGINX neustarten
systemctl restart nginx
```

**Pro-Tipp:** `nginx -t` ist dein bester Freund! Testet die Config ohne den Service zu killen.

---

##### üîí SSL/TLS - Gr√ºnes Schloss f√ºr alle!
**Status:** ‚úÖ Sicher und verschl√ºsselt!

Let's Encrypt ist einfach genial - kostenloses SSL f√ºr alle! Certbot macht den ganzen Prozess super easy:

```bash
# Certbot installieren
apt install -y certbot python3-certbot-nginx

# Magic happens here
certbot --nginx -d explorer.example.com --non-interactive --agree-tos -m admin@example.com
```

Die automatisch generierte SSL-Config von Certbot war okay, aber ich hab sie noch etwas getunt:

```nginx
# Erweiterte SSL-Konfiguration
server {
    listen 443 ssl http2;
    server_name explorer.example.com;
    
    # Certbot managed
    ssl_certificate /etc/letsencrypt/live/explorer.example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/explorer.example.com/privkey.pem;
    
    # Mozilla Intermediate Config - der Sweet Spot
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    
    # HSTS - einmal HTTPS, immer HTTPS!
    add_header Strict-Transport-Security "max-age=63072000" always;
    
    # Security Headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    
    # Rest der Config...
    location / {
        proxy_pass http://localhost:8080;
        # ... proxy settings ...
    }
}

# HTTP zu HTTPS Redirect
server {
    listen 80;
    server_name explorer.example.com;
    return 301 https://$server_name$request_uri;
}
```

**Achievement unlocked:** SSL Labs Test mit A-Rating! üéâ

![SSL Labs Rating](docs/images/ssl_labs_rating.png)
*SSL Labs gibt uns ein solides A - Mission accomplished!*

---

##### üöÄ CI/CD Pipeline - Automatisierung FTW!
**Status:** ‚úÖ Deployment auf Knopfdruck!

Die GitHub Actions Pipeline war mein Baby in diesem Sprint. Nach etlichen Iterationen (und vielen failed Builds) hab ich endlich eine Pipeline, die rockt:

```yaml
# .github/workflows/deploy-prod.yml
name: Rust CI/CD Pipeline (Production)

on:
  push:
    branches: [main]
  workflow_dispatch:  # Manuelles Triggern ist nice to have

env:
  APP_NAME: penumbra-explorer
  SERVER_USER: deploy-penumbra-explorer
  SERVER_HOST: ${{ secrets.SERVER_HOST_PROD }}
  RUST_VERSION: 1.83.0

jobs:
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: ${{ env.RUST_VERSION }}
          components: rustfmt, clippy
      
      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2
        with:
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
      
      - name: Check formatting
        run: cargo fmt --all -- --check
      
      - name: Run clippy
        run: cargo clippy --all-targets --all-features -- -D warnings

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: code-quality
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: ${{ env.RUST_VERSION }}
      
      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2
      
      - name: Run tests
        run: |
          cargo test --all --verbose
          cargo test --all --release

  build-and-deploy:
    name: Build and Deploy
    runs-on: ubuntu-latest
    needs: [code-quality, test]
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: ${{ env.APP_NAME }}:latest,${{ env.APP_NAME }}:${{ github.sha }}
          outputs: type=docker,dest=/tmp/${{ env.APP_NAME }}.tar
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            RUST_VERSION=${{ env.RUST_VERSION }}
      
      - name: Deploy to server
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ env.SERVER_HOST }}
          username: ${{ env.SERVER_USER }}
          key: ${{ secrets.DEPLOY_SSH_KEY }}
          script: |
            # Backup current version
            docker tag ${{ env.APP_NAME }}:latest ${{ env.APP_NAME }}:backup || true
            
            # Load new image
            docker load -i /tmp/${{ env.APP_NAME }}.tar
            
            # Stop old container gracefully
            docker stop -t 30 ${{ env.APP_NAME }} || true
            docker rm ${{ env.APP_NAME }} || true
            
            # Run new container
            docker run -d \
              --name ${{ env.APP_NAME }} \
              --network penumbra-prod-net \
              -p 8080:8080 \
              -e RUST_LOG=info \
              -e SOURCE_DB_URL="${{ secrets.SOURCE_DB_URL }}" \
              -e DEST_DB_URL="${{ secrets.DEST_DB_URL }}" \
              -v /home/${{ env.SERVER_USER }}/data:/app/data \
              --restart unless-stopped \
              --health-cmd="curl -f http://localhost:8080/health || exit 1" \
              --health-interval=30s \
              --health-timeout=10s \
              --health-retries=3 \
              ${{ env.APP_NAME }}:latest
            
            # Wait for health check
            sleep 10
            
            # Verify deployment
            if curl -f http://localhost:8080/health; then
              echo "‚úÖ Deployment successful!"
              docker rmi ${{ env.APP_NAME }}:backup || true
            else
              echo "‚ùå Deployment failed, rolling back..."
              docker stop ${{ env.APP_NAME }} || true
              docker rm ${{ env.APP_NAME }} || true
              docker tag ${{ env.APP_NAME }}:backup ${{ env.APP_NAME }}:latest
              exit 1
            fi
```

Das Highlight: Multi-stage Docker Builds! Von 1.2GB auf 80MB runter - das nenn ich Optimierung!

```dockerfile
# Multi-stage Dockerfile f√ºr optimale Gr√∂sse
FROM rust:1.83-slim AS builder

# Build dependencies installieren
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Dependencies cachen
COPY Cargo.toml Cargo.lock ./
RUN mkdir src && echo "fn main() {}" > src/main.rs
RUN cargo build --release && rm -rf src

# Source code kopieren und bauen
COPY . .
RUN touch src/main.rs && cargo build --release

# Runtime image
FROM debian:bookworm-slim

RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Binary kopieren
COPY --from=builder /app/target/release/penumbra-explorer /app/

# User f√ºr Security
RUN useradd -m -u 1001 -U appuser && chown -R appuser:appuser /app
USER appuser

EXPOSE 8080

CMD ["./penumbra-explorer"]
```

**Stolzer Moment:** Der erste automatische Deploy nach einem Push - es hat einfach funktioniert! üöÄ

---

##### üìö Dokumentation - F√ºr Future-Me
**Status:** ‚úÖ Alles dokumentiert!

Ich hab wirklich versucht, alles zu dokumentieren. Jeder Schritt, jede Konfiguration, jedes "Warum". Die README ist jetzt ein kleines Buch geworden, aber hey - besser zu viel als zu wenig!

**Was ich dokumentiert hab:**
- ‚úì Komplette Server-Setup-Anleitung (mit allen Befehlen)
- ‚úì Docker & NGINX Configs mit Kommentaren
- ‚úì Troubleshooting-Guide (aus eigenen Fehlern gelernt)
- ‚úì Secrets Management (wie man es RICHTIG macht)
- ‚úì Deployment-Prozess Schritt f√ºr Schritt
- ‚úì Rollback-Strategie

---

#### Sprint 2 Review - Der Reality Check

Am 02.06. ist Review-Time!

**Was ich pr√§sentiert hab:**

**Die Zahlen:**
| Metrik | Wert |
|--------|------|
| Geplant | 21 Story Points |
| Geschafft | 21 Story Points |
| Sprint Goal erreicht? | Hell yes! üí™ |

**Feedback von Corrado:**


---

#### Challenges - Was mich fast zur Verzweiflung gebracht hat

##### 1. üì¶ Docker Images waren RIESIG
- **Problem:** Erste Version: 1.2GB (autsch!)
- **Debugging:** `docker history` zeigte mir die Layer-Gr√∂ssen
- **L√∂sung:** Multi-stage Builds implementiert
- **Resultat:** 80MB (so muss das!)

##### 2. üîë SSH in GitHub Actions
- **Problem:** "Permission denied" - der Klassiker
- **Debugging:** Stundenlang Logs durchforstet
- **L√∂sung:** Separater Deploy-Key mit eingeschr√§nkten Rechten
- **Learning:** Niemals den privaten Key committen (obviously!)

##### 3. üè• Container Health Checks
- **Problem:** Container brauchte 30 Sekunden zum Starten
- **Symptom:** Pipeline dachte: "Tot!" und brach ab
- **Fix:** L√§ngere Timeouts und smartere Checks
- **Bonus:** Jetzt mit Graceful Shutdown!

---

#### Was ich gelernt hab

1. **Multi-stage Builds sind PFLICHT f√ºr Rust** - Die Gr√∂ssenersparnis ist enorm!
2. **Immer Health Checks einbauen** - Besser einmal zu viel als einmal zu wenig
3. **Secrets Management von Anfang an planen** - Nachtr√§glich ist's m√ºhsam
4. **Dokumentation w√§hrend der Arbeit schreiben** - Nicht danach!
5. **nginx -t vor jedem Restart** - Hat mir mehrmals den Arsch gerettet

---

#### Ausblick auf Sprint 3

Jetzt kommt der spannende Teil - Blue-Green Deployment! 
- üîÑ Keine Downtime mehr
- ‚Ü©Ô∏è Automatische Rollbacks
- üìä Erweiterte Monitoring-Features
- üéØ The whole nine yards!

Ich freu mich drauf!

---

#### Mein Fazit

Sprint 2 war intensiv, aber mega lehrreich. Die Basis steht jetzt bombenfest. Klar, es war nicht immer einfach (looking at you, Docker Image Size!), aber jedes gel√∂ste Problem hat mich weitergebracht. 

Die Infrastruktur l√§uft stabil, die Pipeline ist smooth, und ich hab dabei viel gelernt. Ready f√ºr Sprint 3! üöÄ

![Pipeline Success](docs/images/github_actions_success.png)
*Gr√ºne H√§kchen soweit das Auge reicht - ein sch√∂ner Anblick!*
---
<p align="left">
  <img src="docs/images/pklabs_logo.png" alt="PK Labs Logo">
</p>
*Dieses Projekt wird im Rahmen der TBZ Semesterarbeit f√ºr PK Labs umgesetzt.*

*Letzte Aktualisierung: 05.05.2025*
