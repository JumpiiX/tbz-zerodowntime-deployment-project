# Zero-Downtime Deployment eines Rust-basierten Blockchain-Indexers

<p align="center">
  <img src="docs/images/penumbra_logo.png" alt="Penumbra Logo">
</p>

Dieses Projekt implementiert ein Zero-Downtime Deployment-System fÃ¼r  Penumbra Blockchain Explorer, der kryptographische Blockchain-Daten fÃ¼r Endbenutzer verstÃ¤ndlich visualisiert. [Penumbra](https://penumbra.zone/) ist eine datenschutzorientierte Zero-Knowledge-Blockchain, deren komplexe Datenstrukturen ohne spezielle Indexierung und Aufbereitung fÃ¼r normale Anwender nicht lesbar wÃ¤ren.


## Wichtige Links

| Beschreibung | Link |
|--------------|------|
| **Doku-Repository** | [tbz-zerodowntime-deployment-project](https://github.com/JumpiiX/tbz-zerodowntime-deployment-project) |
| **Rust Blockchain Indexer** | [penumbra-explorer-backend](https://github.com/pk-labs/penumbra-explorer-backend) |
| **Scrum Board** | [GitHub Projects Board](https://github.com/users/JumpiiX/projects/2/views/1) |
| **Roadmap** | [Projekt Roadmap](https://github.com/users/JumpiiX/projects/2/views/4) |
| **Sprints** | [Milestones Ãœbersicht](https://github.com/JumpiiX/tbz-zerodowntime-deployment-project/milestones) |

## Inhaltsverzeichnis

1. [EinfÃ¼hrung und Problemstellung](#einfÃ¼hrung-und-problemstellung)
2. [Projektziele](#projektziele)
3. [Projektmanagement](#projektmanagement)
4. [Sprints und Fortschritt](#sprints-und-fortschritt)
5. [Fazit](#fazit)

## EinfÃ¼hrung und Problemstellung

### Problemstellung

Blockchain-Daten mÃ¼ssen kontinuierlich und zuverlÃ¤ssig indiziert werden, um sie in Echtzeit fÃ¼r Endanwender bereitzustellen â€“ beispielsweise in einem Block Explorer. Da sich das Datenmodell oder die Indizierungslogik regelmÃ¤ssig Ã¤ndert, mÃ¼ssen bestehende Indexer-Instanzen ersetzt und Daten neu aufgebaut werden (Reindexing).

Ohne geeignete Strategie fÃ¼hrt dies zu:
- **Downtime** fÃ¼r Endnutzer
- **Inkonsistenten Daten** wÃ¤hrend der Umschaltung
- **Benutzerfehlern** durch unvollstÃ¤ndige Daten

### FÃ¼r wen lÃ¶sen wir das Problem?

Mein aktueller Arbeitgeber [PK Labs](https://www.pklabs.me/) benÃ¶tigt eine LÃ¶sung, um unsere Rust-basierten Blockchain-Indexer fÃ¼r die Penumbra-Blockchain ohne Unterbrechungen aktualisieren zu kÃ¶nnen. Dies betrifft sowohl:
- Interne Entwicklungsteams, die kontinuierlichen Zugriff auf Blockchain-Daten benÃ¶tigen
- Externe Kunden und Nutzer, die auf die API des Indexers fÃ¼r ihre Anwendungen angewiesen sind
- Unseren [Penumbra Blockchain Explorer](https://explorer.penumbra.zone/) 

### Herausforderungen bei aktuellen Deployments

Die bestehenden Deployment-Prozesse bei PK Labs haben folgende Herausforderungen:

| Herausforderung | Auswirkung | HÃ¤ufigkeit |
|-----------------|------------|------------|
| Downtime wÃ¤hrend Updates | Nutzer kÃ¶nnen nicht auf den Explorer zugreifen | Bei jedem Update (ca. 2x pro Woche) |
| Inkonsistente Daten | Falsche oder unvollstÃ¤ndige Informationen werden angezeigt | Bei jedem Reindexing-Vorgang |
| Manuelle Ãœberwachung | Entwickler mÃ¼ssen den Synchronisationsprozess Ã¼berwachen | Dauerhaft wÃ¤hrend Updates |
| Kein automatischer Rollback | Bei Fehlern ist manuelles Eingreifen erforderlich | Bei ca. 15% der Deployments |

### LÃ¶sungsansatz: Blue-Green Deployment

Die LÃ¶sung fÃ¼r die genannten Herausforderungen ist ein **Blue-Green Deployment**-Konzept:

1. **Parallel-Betrieb:** Eine neue Indexer-Instanz (Green) wird parallel zur laufenden Instanz (Blue) gestartet
2. **Hintergrund-Synchronisation:** Die neue Instanz synchronisiert die Blockchain-Daten, wÃ¤hrend die alte weiter im Produktivbetrieb ist
3. **Automatische Erkennung:** Ein Monitoring-System erkennt, wann die neue Instanz vollstÃ¤ndig synchronisiert ist
4. **Nahtlose Umschaltung:** Ein NGINX Reverse Proxy leitet den Traffic ohne Unterbrechung zur neuen Instanz um
5. **Fallback-Option:** Bei Problemen kann sofort zur alten Instanz zurÃ¼ckgeschaltet werden

#### Komponenten der LÃ¶sung

| Komponente | Zweck | Technologie |
|------------|-------|-------------|
| **NGINX Reverse Proxy** | Traffic-Steuerung zwischen Umgebungen | NGINX mit dynamischer Konfiguration |
| **Docker Container** | Isolierte Umgebungen fÃ¼r den Indexer | Docker, Docker Compose |
| **Monitoring-Script** | Ãœberwachung des Synchronisationsstatus | Shell-Script mit Docker-Abfragen |
| **Switch-Mechanismus** | Automatisierte Umschaltung | Shell-Script zur NGINX-Konfiguration |
| **Rollback-Mechanismus** | Sichere RÃ¼ckkehr zur vorherigen Version | Automatisiertes Script mit Datenbank-Checks |

## Projektplanung - Gantt Chart

```mermaid
%%{init: {
  'theme': 'base',
  'themeVariables': {
    'primaryColor': '#2b2b2b',
    'primaryTextColor': '#ffffff',
    'primaryBorderColor': '#555555',
    'lineColor': '#888888',
    'sectionBkgColor': '#1e1e1e',
    'altSectionBkgColor': '#2a2a2a',
    'gridColor': '#444444',
    'section0': '#1e1e1e',
    'section1': '#2a2a2a',
    'section2': '#333333',
    'section3': '#3a3a3a',
    'fontFamily': 'Arial, sans-serif',
    'fontSize': '13px',
    'fontWeight': 'bold',
    'taskTextLightColor': '#1e1e1e' // unsichtbar machen
  }
}}%%
gantt
    title Penumbra Zero-Downtime Deployment Projekt
    dateFormat  YYYY-MM-DD
    axisFormat  %d.%m

    section Projektplanung & Setup
    Erster Schultag                     :done, dummy, 2025-04-02, 1d
    SMART Ziele & Scrum Setup           :done, phase1, 2025-04-14, 2025-04-25
    Sprint 1 Review                     :milestone, m1, 2025-05-09, 0d

    section Infrastruktur-Entwicklung
    Server & Docker Setup               :done, phase2, 2025-05-10, 2025-05-18
    NGINX & SSL Konfiguration           :done, phase3, 2025-05-18, 2025-05-25
    CI/CD Pipeline Entwicklung          :done, phase4, 2025-05-25, 2025-06-02
    Sprint 2 Review                     :milestone, m2, 2025-06-02, 0d

    section Blue-Green Implementation
    Deploy & Monitor Scripts            :done, phase5, 2025-06-03, 2025-06-12
    NGINX Traffic Management            :done, phase6, 2025-06-08, 2025-06-14
    Testing & Dokumentation             :done, phase7, 2025-06-14, 2025-06-20
    Sprint 3 Review                     :milestone, m3, 2025-06-20, 0d

    section Projektabschluss
    PrÃ¤sentationsplanung                :done, phase8, 2025-06-20, 2025-06-25
    Finale Dokumentation                :done, phase9, 2025-06-25, 2025-07-02
    Projektabgabe                       :milestone, m4, 2025-07-09, 0d

```
### Projektvisualisierungen

#### SEUSAG-Diagramm

![SEUSAG-Diagramm](./docs/diagrams/seusagdiagramm.png)
*SEUSAG-Diagramm - Zero-Downtime Deployment System Systemgrenzen und Komponenten der automatisierten CI/CD-Pipeline*

### SEUSAG-Diagramm Beschreibung

#### Ãœbersicht
Das SEUSAG-Diagramm zeigt den vollstÃ¤ndigen Zero-Downtime Deployment-Prozess mit allen beteiligten Komponenten und deren Schnittstellen.

#### Prozessablauf

**1. Entwickler â†’ GitHub (ES01)**
- Entwickler pusht Code-Ã„nderungen zu GitHub
- Erstellt einen neuen Release-Tag

**2. GitHub â†’ CI/CD Pipeline (ES02)**
- GitHub Actions wird durch Release getriggert
- Webhook aktiviert die Build-Pipeline

**3. CI/CD Pipeline â†’ Deployment (IS01)**
- Docker Image wird gebaut
- Deploy.sh Script wird auf Server ausgefÃ¼hrt

**4. Deploy.sh â†’ Monitor.sh (IS02)**
- Deploy Script startet neuen Container in inaktiver Umgebung
- Monitor Script wird gestartet fÃ¼r Health Checks

**5. Monitor.sh â†’ NGINX (IS03)**
- Monitor Script Ã¼berwacht Synchronisations-Status
- Bei "catchup completed" wird NGINX Config angepasst

**6. NGINX â†’ Endbenutzer (ES03)**
- Traffic wird nahtlos zur neuen Version umgeleitet
- Zero-Downtime fÃ¼r alle User garantiert

#### Kernkomponenten
- **deploy.sh**: Orchestriert den gesamten Deployment-Prozess
- **monitor.sh**: Ãœberwacht Health Status und fÃ¼hrt Traffic-Switch durch
- **NGINX Config**: Load Balancer fÃ¼r Blue-Green Umschaltung

#### RÃ¼ckkopplung
Bei Fehlern erfolgt automatischer Rollback zur vorherigen Version Ã¼ber die gleichen Komponenten.

## Projektziele

Die Ziele dieses Projekts sind nach dem SMART-Prinzip definiert:

### 1. Eliminierung von Deployment-bedingten Downtimes
- **Spezifisch:** Implementierung eines Blue-Green Deployment-Systems, das Updates ohne Ausfallzeit ermÃ¶glicht
- **Messbar:** Reduzierung der Downtime von derzeit durchschnittlich 8 Stunden pro Deployment auf 0 Sekunden
- **Attraktiv:** ErhÃ¶hte VerfÃ¼gbarkeit des Blockchain-Explorers (Ziel: 99,9%)
- **Realistisch:** Umsetzbar mit NGINX, Docker und automatisierten Scripts
- **Terminiert:** VollstÃ¤ndig implementiert bis 09.07.2025

### 2. Automatisierung der Deployment-Pipeline
- **Spezifisch:** Entwicklung einer vollautomatischen Deployment-Pipeline vom Code bis zur Produktion
- **Messbar:** Reduzierung des manuellen Aufwands pro Deployment von 45 auf unter 5 Minuten
- **Attraktiv:** Geringere FehleranfÃ¤lligkeit und hÃ¶here Entwicklereffizienz
- **Realistisch:** Umsetzbar mit Shell-Scripts und Docker Compose
- **Terminiert:** Fertigstellung bis Ende Sprint 2 (02.06.2025)

### 3. Implementierung einer zuverlÃ¤ssigen Synchronisationserkennung
- **Spezifisch:** Entwicklung eines Monitoring-Systems zur Erkennung des Indexer-Synchronisationsstatus
- **Messbar:** 100% zuverlÃ¤ssige Erkennung mit einer Fehlertoleranz von maximal 0,1%
- **Attraktiv:** Vermeidung von Dateninkonsistenzen und falschen Umschaltungen
- **Realistisch:** Implementierbar mit API-Abfragen und intelligenten Vergleichsalgorithmen
- **Terminiert:** Abschluss bis Mitte Sprint 3 (15.06.2025)

## Projektmanagement

### Agile Arbeitsweise mit Scrum

FÃ¼r dieses Projekt wird **Scrum** als agile Methodik verwendet aus folgenden GrÃ¼nden:

1. **Iterative Entwicklung:** Die komplexe Natur des Blue-Green Deployments erfordert einen schrittweisen Ansatz, bei dem Komponenten einzeln entwickelt und getestet werden kÃ¶nnen.

2. **RegelmÃ¤ssiges Feedback:** Durch Sprint Reviews mit den Dozenten kann frÃ¼hzeitig wertvolles Feedback eingeholt und in die weitere Entwicklung einbezogen werden.

3. **Transparente Fortschrittsverfolgung:** Das Scrum-Board bietet jederzeit einen klaren Ãœberblick Ã¼ber den aktuellen Projektstand und offene Tasks.

4. **FlexibilitÃ¤t:** Neue Erkenntnisse oder sich Ã¤ndernde Anforderungen kÃ¶nnen schnell in die Projektplanung integriert werden.

#### Anpassungen fÃ¼r Einzelprojekt

Da es sich um ein Einzelprojekt handelt, wurden folgende Anpassungen am klassischen Scrum-Prozess vorgenommen:

| Scrum-Element | Klassische Umsetzung | Anpassung fÃ¼r Einzelprojekt |
|---------------|----------------------|----------------------------|
| **Daily Standup** | TÃ¤gliches Team-Meeting | TÃ¤gliche Selbstreflexion und Fortschrittsdokumentation |
| **Sprint Planning** | Team-Entscheidung | Abstimmung mit Dozenten und eigenstÃ¤ndige Planung |
| **Peer Reviews** | Team-interne Reviews | Dozentenfeedback und Selbstreview anhand von Checklisten |
| **Product Owner** | Dedizierte Rolle | Rolle wird durch Dozenten und selbst Ã¼bernommen |
| **Scrum Master** | Dedizierte Rolle | Selbstorganisation mit regelmÃ¤ssiger Prozessreflexion |

### Definition of Done

Ein Task gilt als abgeschlossen, wenn:

1. Die Implementierung vollstÃ¤ndig ist und alle Akzeptanzkriterien erfÃ¼llt sind
2. Eine umfassende Dokumentation erstellt wurde
3. Tests durchgefÃ¼hrt und dokumentiert wurden (mit Testprotokoll)
4. Der Code/die Ã„nderung ist ins Repository eingecheckt

## Sprints und Fortschritt

### Sprint 1: Projektsetup und Grundlagen (14.04 - 09.05)

#### Sprint 1 Planung

Die Planung fÃ¼r Sprint 1 wurde am 14.04.2025 durchgefÃ¼hrt und folgende Ziele und Tasks wurden definiert:

**Sprint-Ziel:** Einrichtung der Projektgrundlagen und Dokumentation der Ausgangslage fÃ¼r das Zero-Downtime Deployment-System.


Die Planung wurde mit Corrado und Boris (Projektexperte) abgestimmt, und am 17.04.2025 erhielt ich das endgÃ¼ltige "Go" fÃ¼r mein Projekt.

![Sprint 1 Start](docs/images/startsprint1.png)
*Sprint 1 GitHub Board - Projektsetup und Grundlagen Planung*

#### Sprint 1 DurchfÃ¼hrung und Ergebnisse

WÃ¤hrend Sprint 1 wurden folgende Ergebnisse erzielt:

- **GitHub Repository** eingerichtet mit grundlegender Dokumentationsstruktur
- **GitHub Projects Board** als Scrum-Board konfiguriert mit User Stories und Akzeptanzkriterien
- **AusfÃ¼hrliche Dokumentation** der Problemstellung, des LÃ¶sungsansatzes und der SMART-Ziele im README
- **Klare BegrÃ¼ndung** fÃ¼r die Wahl von Scrum als agile Methodik und notwendige Anpassungen dokumentiert
- **Visualisierung** des Zero-Downtime Deployment-Prozesses mittels Diagramm
- **Definition of Done** etabliert und dokumentiert
- **Sprint 2 Planung** mit konkreten Tasks vorbereitet

#### Sprint 1 Review (09.05.2025)

Der Sprint 1 Review wurde am 09.05.2025 mit Corrado Parisi durchgefÃ¼hrt:

**Agenda:**
1. Projektstand
2. Erledigte Tasks
3. Herausforderungen 
4. Demo: Repository & Diagramm
5. Sprint 2 Planung
6. Fragen & Feedback

**PrÃ¤sentierte Ergebnisse:**
- VollstÃ¤ndiges README mit Problemstellung, LÃ¶sungsansatz und SMART-Zielen
- GitHub Repository mit Strukturierung und Dokumentation
- GitHub Projects Board mit User Stories und Akzeptanzkriterien

**Feedback:**
- Corrado Parisi hob die Wahl eines anspruchsvollen Projekts positiv hervor
- Er lobte die gut definierten Akzeptanzkriterien und die QualitÃ¤t der SMART-Ziele

**Vereinbarte Anpassungen:**
- Erstellung eines Gantt-Charts fÃ¼r die Projektplanung
- Entwicklung eines SEUSAG-Diagramms zur Visualisierung der Systemkomponenten
- Standardisierung des User Story-Formats nach dem Schema "Als [Rolle] mÃ¶chte ich [FunktionalitÃ¤t], damit [Nutzen]"

![Sprint 1 Ende](docs/images/startsprint2.png)
*Sprint 1 abgeschlossen - Alle User Stories erfolgreich implementiert, bereit fÃ¼r Sprint 2*

**Reflexion:**
Die Dokumentation der Problemstellung und des LÃ¶sungsansatzes war erfolgreich. Die User Stories mit ihren detaillierten Akzeptanzkriterien wurden besonders positiv bewertet. Die Entwicklung eines klaren Deployment-Flow-Diagramms nahm mehr Zeit in Anspruch als geplant, wurde aber mit gutem Ergebnis abgeschlossen. Die Anpassung von Scrum fÃ¼r ein Einzelprojekt stellte eine Herausforderung dar, wurde aber durch die dokumentierten Anpassungen gut gelÃ¶st.

### Sprint 1 Retrospektive

![Sprint 1 Retrospektive](docs/images/sprint1retrospective.png)
*Sprint 1 Retrospektive - Fokus auf Dokumentation und Visualisierung*

### Sprint 2: Server-Infrastruktur (10.05 - 02.06)

#### Sprint 2 Planung

Nach dem erfolgreichen Sprint 1 Review war ich richtig motiviert, endlich mit der technischen Umsetzung zu beginnen. Corrado hatte mir wertvolles Feedback gegeben, und jetzt ging es darum, die Theorie in die Praxis umzusetzen.

**Sprint-Ziel:** Eine funktionierende Production-Umgebung aufbauen, in der unser Penumbra Blockchain Indexer zuverlÃ¤ssig lÃ¤uft - mit automatischem Deployment und allem Drum und Dran.

![Sprint 2 Start](docs/images/startsprint2.png)
*Sprint 2 GitHub Board - Server-Infrastruktur Tasks bereit*

**Was ich mir fÃ¼r Sprint 2 vorgenommen hatte:**

##### 1. Ubuntu Server Setup (3 Story Points)
- **Als** Software Engineer **mÃ¶chte ich** einen Ubuntu-Server in der Hetzner Cloud einrichten, **damit** ich eine stabile und leistungsfÃ¤hige Umgebung fÃ¼r den Blockchain-Indexer bereitstellen kann.
- *Das war der erste wichtige Schritt - ohne Server lÃ¤uft nichts!*

##### 2. Docker Installation (2 Story Points)
- **Als** Software Engineer **mÃ¶chte ich** Docker und Docker Compose auf dem Server installieren und konfigurieren, **damit** ich containerisierte Anwendungen fÃ¼r den Blockchain-Indexer bereitstellen kann.
- *Docker macht das Leben so viel einfacher...*

##### 3. NGINX Reverse Proxy (5 Story Points)
- **Als** Software Engineer **mÃ¶chte ich** NGINX als Reverse Proxy einrichten, **damit** ich eine zentrale Stelle fÃ¼r die Verkehrsweiterleitung zum Docker Container habe.
- *Der Klassiker fÃ¼r Production-Setups!*

##### 4. TLS/SSL Implementierung (3 Story Points)
- **Als** Software Engineer **mÃ¶chte ich** TLS/SSL mit Let's Encrypt implementieren, **damit** die Kommunikation zwischen Clients und dem Backend-Service verschlÃ¼sselt und sicher ist.
- *Sicherheit first - niemand will unverschlÃ¼sselte APIs!*

##### 5. CI/CD Pipeline (5 Story Points)
- **Als** Software Engineer **mÃ¶chte ich** einen GitHub Workflow fÃ¼r Continuous Integration und Deployment einrichten, **damit** Code-Ã„nderungen automatisch getestet, gebaut und auf dem Server bereitgestellt werden.
- *Automatisierung ist der SchlÃ¼ssel zu meiner Sanity...*

##### 6. Dokumentation (3 Story Points)
- **Als** Software Engineer **mÃ¶chte ich** die Server-Infrastruktur und alle Konfigurationen umfassend dokumentieren, **damit** die Umgebung leicht nachvollziehbar, wartbar und bei Bedarf reproduzierbar ist.
- *Future-Me wird mir danken!*

**Geplante Velocity:** 21 Story Points - sportlich, aber machbar!

---

#### Sprint 2 - So lief es wirklich

##### ğŸ–¥ï¸ Ubuntu Server Setup - Der Anfang von allem
**Status:** âœ… Done!

Ich hab mir einen schicken Hetzner Cloud Server geklickt - Ubuntu 24.04 LTS, weil ich auf Nummer sicher gehen wollte. Die Specs:

```bash
# Mein neues Zuhause fÃ¼r den Indexer
OS: Ubuntu 24.04 LTS (die gute alte LTS!)
CPU: 2 vCPU (sollte reichen)
RAM: 4 GB (Rust ist ja memory-efficient)
Storage: 40 GB NVMe SSD (schnell muss es sein)
Location: NÃ¼rnberg (fÃ¼r die niedrige Latenz)
```

Das Setup war straightforward, aber ich hab natÃ¼rlich direkt die Firewall vergessen und mich fast ausgesperrt. Zum GlÃ¼ck hatte ich noch eine Console-Session offen!

**Was ich gemacht hab:**

```bash
# SSH-Key kopieren (sicherer als PasswÃ¶rter!)
ssh-copy-id -i ~/.ssh/id_rsa.pub root@server-ip

# System updaten
apt update && apt upgrade -y

# Basis-Packages installieren
apt install -y curl wget git build-essential htop vim

# Firewall einrichten (diesmal richtig!)
ufw allow 22/tcp    # SSH
ufw allow 80/tcp    # HTTP
ufw allow 443/tcp   # HTTPS
ufw enable

# Zeitzone setzen
timedatectl set-timezone Europe/Zurich
```

**Learning:** Immer erst die Firewall-Regeln testen, BEVOR man sie aktiviert...

![Server Setup Complete](docs/images/server_setup_terminal.png)
*Terminal-Screenshot nach erfolgreichem Setup*

---

##### ğŸ³ Docker - Container sind Leben
**Status:** âœ… Geschafft!

Docker Installation war ein Kinderspiel - die Docs von Docker sind echt gut. Hab die neueste Version installiert und direkt ein eigenes Netzwerk fÃ¼r unseren Indexer erstellt:

```bash
# Docker GPG Key hinzufÃ¼gen
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /usr/share/keyrings/docker-archive-keyring.gpg

# Docker Repository hinzufÃ¼gen
echo "deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/docker-archive-keyring.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null

# Docker installieren
apt update
apt install -y docker-ce docker-ce-cli containerd.io docker-compose-plugin

# Das Netzwerk fÃ¼r unseren Penumbra Explorer
docker network create penumbra-prod-net

# Deploy-User einrichten (Security first!)
sudo useradd -m -s /bin/bash deploy-penumbra-explorer
sudo usermod -aG docker deploy-penumbra-explorer
```

Der Deploy-User war wichtig - ich wollte nicht, dass GitHub Actions als root lÃ¤uft. Das wÃ¤re echt keine gute Idee gewesen.

**Test-Moment:** 
```bash
docker run hello-world
```
Das befriedigendste "Hello from Docker!" ever! ğŸ‰

---

##### ğŸ”€ NGINX - Der Traffic-Dirigent
**Status:** âœ… LÃ¤uft wie geschmiert!

NGINX einzurichten war... interessant. Ich hab bestimmt drei Mal die Konfiguration verkackt, bis ich gemerkt hab, dass ich den symbolischen Link vergessen hatte. Classic!

```bash
# NGINX installieren
apt install -y nginx

# Konfiguration erstellen
vim /etc/nginx/sites-available/penumbra-explorer
```

```nginx
# /etc/nginx/sites-available/penumbra-explorer
server {
    listen 80;
    server_name explorer.example.com;  # Keine echte Domain hier ;)
    
    # Hauptroute zum Indexer
    location / {
        proxy_pass http://localhost:8080;
        proxy_set_header Host $host;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
        
        # WebSocket support - wichtig fÃ¼r Live-Updates!
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection "upgrade";
        
        # Timeouts fÃ¼r lange Blockchain-Queries
        proxy_read_timeout 300s;
        proxy_connect_timeout 75s;
    }
    
    # Health-Check Endpoint
    location /health {
        proxy_pass http://localhost:8080/health;
        access_log off;  # Spam vermeiden
    }
}
```

```bash
# Konfiguration aktivieren
ln -s /etc/nginx/sites-available/penumbra-explorer /etc/nginx/sites-enabled/

# Config testen (Life saver!)
nginx -t

# NGINX neustarten
systemctl restart nginx
```

**Pro-Tipp:** `nginx -t` ist dein bester Freund! Testet die Config ohne den Service zu killen.

---

##### ğŸ”’ SSL/TLS - GrÃ¼nes Schloss fÃ¼r alle!
**Status:** âœ… Sicher und verschlÃ¼sselt!

Let's Encrypt ist einfach genial - kostenloses SSL fÃ¼r alle! Certbot macht den ganzen Prozess super easy:

```bash
# Certbot installieren
apt install -y certbot python3-certbot-nginx

# Magic happens here
certbot --nginx -d explorer.example.com --non-interactive --agree-tos -m admin@example.com
```

Die automatisch generierte SSL-Config von Certbot war okay, aber ich hab sie noch etwas getunt:

```nginx
# Erweiterte SSL-Konfiguration
server {
    listen 443 ssl http2;
    server_name explorer.example.com;
    
    # Certbot managed
    ssl_certificate /etc/letsencrypt/live/explorer.example.com/fullchain.pem;
    ssl_certificate_key /etc/letsencrypt/live/explorer.example.com/privkey.pem;
    
    # Mozilla Intermediate Config - der Sweet Spot
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384;
    ssl_prefer_server_ciphers off;
    
    # HSTS - einmal HTTPS, immer HTTPS!
    add_header Strict-Transport-Security "max-age=63072000" always;
    
    # Security Headers
    add_header X-Frame-Options "SAMEORIGIN" always;
    add_header X-Content-Type-Options "nosniff" always;
    add_header X-XSS-Protection "1; mode=block" always;
    
    # Rest der Config...
    location / {
        proxy_pass http://localhost:8080;
        # ... proxy settings ...
    }
}

# HTTP zu HTTPS Redirect
server {
    listen 80;
    server_name explorer.example.com;
    return 301 https://$server_name$request_uri;
}
```

**Achievement unlocked:** SSL Labs Test mit A-Rating! ğŸ‰

![SSL Labs Rating](docs/images/ssl_labs_rating.png)
*SSL Labs gibt uns ein solides A - Mission accomplished!*

---

##### ğŸš€ CI/CD Pipeline - Automatisierung FTW!
**Status:** âœ… Deployment auf Knopfdruck!

Die GitHub Actions Pipeline war mein Baby in diesem Sprint. Nach etlichen Iterationen (und vielen failed Builds) hab ich endlich eine Pipeline, die rockt:

```yaml
# .github/workflows/deploy-prod.yml
name: Rust CI/CD Pipeline (Production)

on:
  push:
    branches: [main]
  workflow_dispatch:  # Manuelles Triggern ist nice to have

env:
  APP_NAME: penumbra-explorer
  SERVER_USER: deploy-penumbra-explorer
  SERVER_HOST: ${{ secrets.SERVER_HOST_PROD }}
  RUST_VERSION: 1.83.0

jobs:
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: ${{ env.RUST_VERSION }}
          components: rustfmt, clippy
      
      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2
        with:
          key: ${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}
      
      - name: Check formatting
        run: cargo fmt --all -- --check
      
      - name: Run clippy
        run: cargo clippy --all-targets --all-features -- -D warnings

  test:
    name: Run Tests
    runs-on: ubuntu-latest
    needs: code-quality
    steps:
      - name: Checkout repository
        uses: actions/checkout@v4
      
      - name: Install Rust toolchain
        uses: dtolnay/rust-toolchain@stable
        with:
          toolchain: ${{ env.RUST_VERSION }}
      
      - name: Cache dependencies
        uses: Swatinem/rust-cache@v2
      
      - name: Run tests
        run: |
          cargo test --all --verbose
          cargo test --all --release

  build-and-deploy:
    name: Build and Deploy
    runs-on: ubuntu-latest
    needs: [code-quality, test]
    if: github.ref == 'refs/heads/main'
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
      
      - name: Set up Docker Buildx
        uses: docker/setup-buildx-action@v3
      
      - name: Build Docker image
        uses: docker/build-push-action@v5
        with:
          context: .
          push: false
          tags: ${{ env.APP_NAME }}:latest,${{ env.APP_NAME }}:${{ github.sha }}
          outputs: type=docker,dest=/tmp/${{ env.APP_NAME }}.tar
          cache-from: type=gha
          cache-to: type=gha,mode=max
          build-args: |
            RUST_VERSION=${{ env.RUST_VERSION }}
      
      - name: Deploy to server
        uses: appleboy/ssh-action@v1.0.0
        with:
          host: ${{ env.SERVER_HOST }}
          username: ${{ env.SERVER_USER }}
          key: ${{ secrets.DEPLOY_SSH_KEY }}
          script: |
            # Backup current version
            docker tag ${{ env.APP_NAME }}:latest ${{ env.APP_NAME }}:backup || true
            
            # Load new image
            docker load -i /tmp/${{ env.APP_NAME }}.tar
            
            # Stop old container gracefully
            docker stop -t 30 ${{ env.APP_NAME }} || true
            docker rm ${{ env.APP_NAME }} || true
            
            # Run new container
            docker run -d \
              --name ${{ env.APP_NAME }} \
              --network penumbra-prod-net \
              -p 8080:8080 \
              -e RUST_LOG=info \
              -e SOURCE_DB_URL="${{ secrets.SOURCE_DB_URL }}" \
              -e DEST_DB_URL="${{ secrets.DEST_DB_URL }}" \
              -v /home/${{ env.SERVER_USER }}/data:/app/data \
              --restart unless-stopped \
              --health-cmd="curl -f http://localhost:8080/health || exit 1" \
              --health-interval=30s \
              --health-timeout=10s \
              --health-retries=3 \
              ${{ env.APP_NAME }}:latest
            
            # Wait for health check
            sleep 10
            
            # Verify deployment
            if curl -f http://localhost:8080/health; then
              echo "âœ… Deployment successful!"
              docker rmi ${{ env.APP_NAME }}:backup || true
            else
              echo "âŒ Deployment failed, rolling back..."
              docker stop ${{ env.APP_NAME }} || true
              docker rm ${{ env.APP_NAME }} || true
              docker tag ${{ env.APP_NAME }}:backup ${{ env.APP_NAME }}:latest
              exit 1
            fi
```

Das Highlight: Multi-stage Docker Builds! Von 1.2GB auf 80MB runter - das nenn ich Optimierung!

```dockerfile
# Multi-stage Dockerfile fÃ¼r optimale GrÃ¶sse
FROM rust:1.83-slim AS builder

# Build dependencies installieren
RUN apt-get update && apt-get install -y \
    pkg-config \
    libssl-dev \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Dependencies cachen
COPY Cargo.toml Cargo.lock ./
RUN mkdir src && echo "fn main() {}" > src/main.rs
RUN cargo build --release && rm -rf src

# Source code kopieren und bauen
COPY . .
RUN touch src/main.rs && cargo build --release

# Runtime image
FROM debian:bookworm-slim

RUN apt-get update && apt-get install -y \
    ca-certificates \
    libssl3 \
    curl \
    && rm -rf /var/lib/apt/lists/*

WORKDIR /app

# Binary kopieren
COPY --from=builder /app/target/release/penumbra-explorer /app/

# User fÃ¼r Security
RUN useradd -m -u 1001 -U appuser && chown -R appuser:appuser /app
USER appuser

EXPOSE 8080

CMD ["./penumbra-explorer"]
```

**Stolzer Moment:** Der erste automatische Deploy nach einem Push - es hat einfach funktioniert! ğŸš€

---

##### ğŸ“š Dokumentation - FÃ¼r Future-Me
**Status:** âœ… Alles dokumentiert!

Ich hab wirklich versucht, alles zu dokumentieren. Jeder Schritt, jede Konfiguration, jedes "Warum".

**Was ich dokumentiert hab:**
- âœ“ Komplette Server-Setup-Anleitung (mit allen Befehlen)
- âœ“ Docker & NGINX Configs mit Kommentaren
- âœ“ Troubleshooting-Guide (aus eigenen Fehlern gelernt)
- âœ“ Secrets Management (wie man es RICHTIG macht)
- âœ“ Deployment-Prozess Schritt fÃ¼r Schritt
- âœ“ Rollback-Strategie

![Sprint 2 Review Board](docs/images/startsprint3.png)
*Sprint 2 Review Demo - Alle Infrastruktur-Tasks abgeschlossen*

---

#### Sprint 2 Review - Der Reality Check

Am 02.06. ist Review-Time!

**Die Zahlen:**
| Metrik | Wert |
|--------|------|
| Geplant | 21 Story Points |
| Geschafft | 21 Story Points |
| Sprint Goal erreicht? | Hell yes! ğŸ’ª |

Demo Ablauf:

GitHub Projects Board gezeigt - Alle User Stories von Sprint 2, TODO â†’ DONE Status
Live Website Demo - Penumbra Explorer lÃ¤uft und ist gerade am Reindexing (verarbeitet alte BlÃ¶cke)
Blockchain Sync Status - Man sieht in Echtzeit wie der Indexer die Chain aufholt
Herausforderungen besprochen - Docker Size, SSH Keys, NGINX Config, Firewall-Drama
Achievements prÃ¤sentiert - Production Infrastructure steht, CI/CD lÃ¤uft automatisch
Sprint 3 Ausblick - Blue-Green Deployment Ziele und Risiken

Feedback von Corrado:
Positives:

"Super Demo!" - Board-Organisation und Live-System haben ihm gefallen
"Du bist auf einem super Weg!" - Projekt lÃ¤uft excellent, gute Struktur
Reindexing-Prozess war interessant zu sehen - echtes Blockchain-System in Action
Herausforderungen authentisch - Firewall-Story fand er lustig, reale Probleme! ğŸ˜…
Sprint 3 Vorbereitung - Blue-Green Concept ist durchdacht

Action Items fÃ¼r Dokumentation:

Screenshots von GitHub Boards hinzufÃ¼gen (Stories TODO â†’ DONE) fÃ¼r alle Sprints
Scrum Retrospektive Diagramm erstellen (More of / Less of / Start doing / Stop doing)
Gantt Chart aktualisieren nach seinem Beispiel
SEUSAG â†’ Architektur-Diagramm erweitern (technische Details wie sein Beispiel)

---

#### Challenges - Was mich fast zur Verzweiflung gebracht hat

##### 1. ğŸ“¦ Docker Images waren RIESIG
- **Problem:** Erste Version: 1.2GB (autsch!)
- **Debugging:** `docker history` zeigte mir die Layer-GrÃ¶ssen
- **LÃ¶sung:** Multi-stage Builds implementiert
- **Resultat:** 80MB (so muss das!)

##### 2. ğŸ”‘ SSH in GitHub Actions
- **Problem:** "Permission denied" - der Klassiker
- **Debugging:** Stundenlang Logs durchforstet
- **LÃ¶sung:** Separater Deploy-Key mit eingeschrÃ¤nkten Rechten
- **Learning:** Niemals den privaten Key committen (obviously!)

##### 3. ğŸ¥ Container Health Checks
- **Problem:** Container brauchte 30 Sekunden zum Starten
- **Symptom:** Pipeline dachte: "Tot!" und brach ab
- **Fix:** LÃ¤ngere Timeouts und smartere Checks
- **Bonus:** Jetzt mit Graceful Shutdown!

---

#### Was ich gelernt hab

1. **Multi-stage Builds sind PFLICHT fÃ¼r Rust** - Die GrÃ¶ssenersparnis ist enorm!
2. **Immer Health Checks einbauen** - Besser einmal zu viel als einmal zu wenig
3. **Secrets Management von Anfang an planen** - NachtrÃ¤glich ist's mÃ¼hsam
4. **Dokumentation wÃ¤hrend der Arbeit schreiben** - Nicht danach!
5. **nginx -t vor jedem Restart** - Hat mir mehrmals den Arsch gerettet

---

#### Ausblick auf Sprint 3

Jetzt kommt der spannende Teil - Blue-Green Deployment! 
- ğŸ”„ Keine Downtime mehr
- â†©ï¸ Automatische Rollbacks
- ğŸ“Š Erweiterte Monitoring-Features
- ğŸ¯ The whole nine yards!

Ich freu mich drauf!

---

#### Mein Fazit

Sprint 2 war intensiv, aber mega lehrreich. Die Basis steht jetzt bombenfest. Klar, es war nicht immer einfach (looking at you, Docker Image Size!), aber jedes gelÃ¶ste Problem hat mich weitergebracht. 

Die Infrastruktur lÃ¤uft stabil, die Pipeline ist smooth, und ich hab dabei viel gelernt. Ready fÃ¼r Sprint 3! ğŸš€


### Sprint 2 Retrospektive

![Sprint 2 Retrospektive](docs/images/sprint2retrospective.png)
*Sprint 2 Retrospektive - Production Infrastructure und Security Learnings*

# ğŸŒ€ Sprint 3: Blue-Green Deployment Implementation (03.06 - 20.06)

## ğŸ§  Sprint 3 Planung

Nach dem erfolgreichen Aufbau der Production-Infrastruktur in Sprint 2 geht es jetzt an den Kern des Projekts: **Zero-Downtime Deployment mit Blue-Green Strategie!** ğŸ”„

Die Basis steht bombenfest:
- Server lÃ¤uft
- CI/CD Pipeline funktioniert
- SSL ist konfiguriert

**Sprint-Ziel:**  
VollstÃ¤ndig funktionierendes **Blue-Green Deployment-System** implementieren, das automatisch zwischen Container-Instanzen switcht und echte Zero-Downtime Deployments ermÃ¶glicht.

---
![Sprint 3 Start](docs/images/startsprint3.png)
*Sprint 3 GitHub Board - Bereit fÃ¼r Blue-Green Implementation*
## ğŸ§© Sprint 3 User Stories

| User Story                                | Story Points |
|-------------------------------------------|--------------|
| Blue-Green Deploy-Skript                  | 8            |
| Container-Synchronisation Monitoring      | 5            |
| NGINX Blue-Green Traffic Management       | 3            |
| CI/CD Pipeline Blue-Green Integration     | 5            |
| Blue-Green Testing                        | 8            |
| Blue-Green Dokumentation                  | 3            |

### ğŸ”¢ Sprint 3 Velocity: 32 Story Points

---

## ğŸš€ Blue-Green Deploy-Skript - Das HerzstÃ¼ck

**Status:** âœ… Funktioniert!  
Das Deploy-Skript war der wichtigste Teil â€“ hier passiert die ganze Blue-Green Magic.

### âœ¨ Key Features:
- Automatische Erkennung der aktiven Umgebung (Blue: Port 8080, Green: Port 8081)
- Sicheres Container-Management mit Cleanup
- Logging fÃ¼r Debugging
- Integration mit dem Monitoring-System

**Learning:** Bash war Ã¼berraschend gut fÃ¼r diesen Use Case.  
Rust wÃ¤re mÃ¶glich gewesen, aber Bash passt besser zu Docker- und NGINX-Kommandos.

---

## ğŸ“Š Sync Monitoring - Der Blockchain-Detektiv

**Status:** âœ… LÃ¤uft automatisch!

### ğŸ¯ Highlights:
- Slack-Benachrichtigungen bei Meilensteinen (z.â€¯B. jede Million BlÃ¶cke)
- ETA-Berechnung basierend auf Sync-Geschwindigkeit
- Automatischer Traffic-Switch bei `"catchup completed"`
- Fortschrittsanzeige mit formatiertem Output

**Favorite Feature:**  
Script sendet Updates nach Slack â€“ das ganze Team sieht den Fortschritt! ğŸ“±

---

## ğŸ”€ NGINX Traffic Management - Zero-Downtime Achievement

**Status:** âœ… Zero-Downtime bestÃ¤tigt!

### ğŸ› ï¸ Upstream-Konfiguration:
Die NGINX-Config war eigentlich straightforward, aber das Upstream-Switching musste perfekt funktionieren.

### âœ… Switching-Logik:
- Comments werden dynamisch gesetzt/entfernt
- `nginx -t` vor jedem Reload (Safety first!)
- `systemctl reload nginx` fÃ¼r Graceful Reload

**Test-Moment:**  
Mit `curl`-Loop wÃ¤hrend Live-Deployment getestet â€“ **kein einziger Request verloren!** ğŸ‰

---

## ğŸ”— GitHub Actions - Release-basierte Deployments

**Status:** âœ… Production-ready!

### âš™ï¸ Workflow:
1. Release erstellen â†’ Pipeline wird getriggert
2. Code-Checks & Tests laufen
3. Docker-Image wird gebaut & deployed
4. `deploy.sh` wird remote ausgefÃ¼hrt
5. `monitor.sh` Ã¼bernimmt automatisch

**Vorteil:**  
Deployments nur bei echten Releases â†’ **kontrollierter Prozess**!

## ğŸ“Š Monitoring und Alerting

**Status:** âœ… Slack-Integration lÃ¤uft!

Das Monitoring-System Ã¼berwacht automatisch den Blockchain-Sync und sendet Live-Updates an Slack:

- **Start-Notification** mit Target-Blockchain-HÃ¶he
- **Progress-Updates** bei jeder Million BlÃ¶cke mit Speed & ETA
- **15-Minuten-Warnung** vor Completion
- **Completion-Alert** wenn Traffic-Switch erfolgt

So sieht es in echt aus:

![Slack Notifications](docs/images/slacknotifications.png)
*Live Slack-Updates wÃ¤hrend eines Production Deployments - das Team sieht jeden Fortschritt in Echtzeit*

---

## ğŸ§ª Blue-Green Testing - Battle-tested

**Status:** âœ… Extensively tested!

### ğŸ” Test-Szenarien:
- âœ… Normaler Flow (Blue â†’ Green â†’ Blue)
- âœ… NGINX-Switch ohne Request-Verlust
- âœ… Container-Failure wÃ¤hrend Sync
- âœ… Rollback bei Deploy-Fehlern
- âœ… Load-Test wÃ¤hrend Traffic-Switch

**Coolster Test:**  
Container im Sync gekillt â†’ Script hat erkannt & Rollback gemacht â†’ **Error-Handling funktioniert!** ğŸ’ª

---

## ğŸ“š Dokumentation - Production-ready

**Status:** âœ… VollstÃ¤ndig dokumentiert!

### ğŸ“„ Inhalte:
- Komplette Blue-Green Architektur
- Nutzung der Scripts + Parameter
- Troubleshooting-Guide
- Monitoring-Setup inkl. Slack
- Rollback-Prozeduren



## Implementierte Scripts und Konfigurationen
Hier sind die drei Kern-Files des Blue-Green Deployment-Systems damit man alles in einem Markdown hat und somit effizienter und schneller bewerten kann als Dozent:

### deploy.sh
```bash
#!/bin/bash
set -e
echo "[$(date +'%Y-%m-%d %H:%M:%S')] Starting blue-green deployment" | tee -a /opt/deployment/deploy.log
# Aktive Umgebung bestimmen
if grep -q "server localhost:8080;" /etc/nginx/conf.d/explorer.conf && ! grep -q "# server localhost:8080;" /etc/nginx/conf.d/explorer.conf; then
  ACTIVE_ENV="blue"
  INACTIVE_ENV="green"
  ACTIVE_PORT=8080
  INACTIVE_PORT=8081
else
  ACTIVE_ENV="green"
  INACTIVE_ENV="blue"
  ACTIVE_PORT=8081
  INACTIVE_PORT=8080
fi
echo "[$(date +'%Y-%m-%d %H:%M:%S')] Active: $ACTIVE_ENV" | tee -a /opt/deployment/deploy.log
echo "[$(date +'%Y-%m-%d %H:%M:%S')] Inactive: $INACTIVE_ENV" | tee -a /opt/deployment/deploy.log
# Docker-Image laden
# Check if Docker image tar file exists
if [ -f "/home/deploy-penumbra-explorer/deployments/penumbra-explorer.tar" ]; then
docker load < /home/deploy-penumbra-explorer/deployments/penumbra-explorer.tar
else
  echo "[$(date +'%Y-%m-%d %H:%M:%S')] Docker image tar not found, using existing image" | tee -a /opt/deployment/deploy.log
fi
# Alten Container stoppen & lÃ¶schen
docker stop penumbra-explorer-$INACTIVE_ENV || true
docker rm penumbra-explorer-$INACTIVE_ENV || true
# Neuen Container starten
docker run -d \
  --name penumbra-explorer-$INACTIVE_ENV \
  --network ${INACTIVE_ENV}-network \
  -p $INACTIVE_PORT:8080 \
  --restart always \
  penumbra-explorer:latest \
  /app/penumbra-explorer \
  -s "postgresql://[DB_USER]:[DB_PASSWORD]@[DB_HOST]:[DB_PORT]/[DB_NAME]?sslmode=require" \
  -d "postgresql://[LOCAL_DB_USER]:[LOCAL_DB_PASSWORD]@postgres-${INACTIVE_ENV}:5432/explorer?sslmode=disable" \
  --genesis-json /app/genesis.json
echo "[$(date +'%Y-%m-%d %H:%M:%S')] New container started for $INACTIVE_ENV" | tee -a /opt/deployment/deploy.log
# Monitoring starten
echo "[$(date +'%Y-%m-%d %H:%M:%S')] Launching monitor script..." | tee -a /opt/deployment/deploy.log
nohup /opt/deployment/monitor.sh "$INACTIVE_ENV" "$ACTIVE_ENV" "$ACTIVE_PORT" "$INACTIVE_PORT" >> /opt/deployment/deploy.log 2>&1 &
```

### monitor.sh
```bash
bash#!/bin/bash
INACTIVE_ENV="$1"
ACTIVE_ENV="$2"
ACTIVE_PORT="$3"
INACTIVE_PORT="$4"
APP_NAME="penumbra-explorer"
LOG_FILE="/opt/deployment/deploy.log"
NGINX_CONF="/etc/nginx/conf.d/explorer.conf"

# Slack configuration - PRODUCTION
SLACK_WEBHOOK_URL="https://hooks.slack.com/services/[WEBHOOK_ID_REMOVED]"
LAST_MILLION_NOTIFIED=0
BLOCK_INTERVAL=1000000  # Notify every million blocks

# Database connection for current block height
DB_URL="postgresql://[DB_USER]:[DB_PASSWORD]@[DB_HOST]:[DB_PORT]/[DB_NAME]?sslmode=require"

# Speed tracking variables
LAST_HEIGHT=0
LAST_TIME=0
SPEED_SAMPLES=()
FIFTEEN_MIN_NOTIFIED=false
HIGHEST_SEEN_BLOCK=0

# Function to send Slack notifications
send_slack_alert() {
  curl -s -X POST -H 'Content-type: application/json' --data "{\"text\":\"$1\"}" "$SLACK_WEBHOOK_URL"
}

# Function to get current chain height
get_current_chain_height() {
  psql "$DB_URL" -t -c "SELECT MAX(height) FROM blocks;" 2>/dev/null | tr -d ' '
}

# Function to get reindexing progress from local database
get_reindex_height() {
  local env=$1
  docker exec postgres-$env psql -U penumbra -d explorer -t -c "SELECT MAX(height) FROM explorer_block_details;" 2>/dev/null | tr -d ' '
}

# Function to format time duration
format_duration() {
  local seconds=$1
  local hours=$((seconds / 3600))
  local minutes=$(((seconds % 3600) / 60))
  
  if [ $hours -gt 0 ]; then
    echo "${hours}h ${minutes}m"
  else
    echo "${minutes}m"
  fi
}

# Function to calculate average speed
calculate_average_speed() {
  local total=0
  local count=${#SPEED_SAMPLES[@]}
  
  if [ $count -eq 0 ]; then
    echo "0"
    return
  fi
  
  for speed in "${SPEED_SAMPLES[@]}"; do
    total=$((total + speed))
  done
  
  echo $((total / count))
}

# === START ===
echo "[$(date +'%Y-%m-%d %H:%M:%S')] MONITOR: Started for $INACTIVE_ENV" >> "$LOG_FILE"

# Get initial chain height
CURRENT_CHAIN_HEIGHT=$(get_current_chain_height)
echo "[$(date +'%Y-%m-%d %H:%M:%S')] MONITOR: Current chain height: $CURRENT_CHAIN_HEIGHT" >> "$LOG_FILE"

# Get initial reindex height to set LAST_MILLION_NOTIFIED correctly
initial_height=$(get_reindex_height "$INACTIVE_ENV")
if [ -n "$initial_height" ] && [ "$initial_height" -gt 0 ]; then
  LAST_MILLION_NOTIFIED=$((initial_height / BLOCK_INTERVAL))
  echo "[$(date +'%Y-%m-%d %H:%M:%S')] MONITOR: Starting from block $initial_height (already past $LAST_MILLION_NOTIFIED million)" >> "$LOG_FILE"
fi

# Send start notification - PRODUCTION
send_slack_alert "ğŸš€ **Prod** server reindexing started for $INACTIVE_ENV environment. Target height: $(printf "%'d" $CURRENT_CHAIN_HEIGHT)"

sleep 120

while true; do
  # Get current height from database
  current_height=$(get_reindex_height "$INACTIVE_ENV")
  current_time=$(date +%s)
  
  if [ -n "$current_height" ] && [ "$current_height" -gt 0 ]; then
    # Update highest seen block
    if [ $current_height -gt $HIGHEST_SEEN_BLOCK ]; then
      HIGHEST_SEEN_BLOCK=$current_height
    fi
    
    # Calculate speed if we have previous data
    if [ $LAST_HEIGHT -gt 0 ] && [ $LAST_TIME -gt 0 ]; then
      blocks_processed=$((current_height - LAST_HEIGHT))
      time_elapsed=$((current_time - LAST_TIME))
      
      if [ $time_elapsed -gt 0 ] && [ $blocks_processed -gt 0 ]; then
        # Blocks per second (multiplied by 1000 for precision)
        current_speed=$((blocks_processed * 1000 / time_elapsed))
        SPEED_SAMPLES+=($current_speed)
        
        # Keep only last 5 samples for moving average
        if [ ${#SPEED_SAMPLES[@]} -gt 5 ]; then
          SPEED_SAMPLES=("${SPEED_SAMPLES[@]:1}")
        fi
      fi
    fi
    
    # Update last values
    LAST_HEIGHT=$current_height
    LAST_TIME=$current_time
    
    # Get current chain height and calculate remaining
    CURRENT_CHAIN_HEIGHT=$(get_current_chain_height)
    blocks_remaining=$((CURRENT_CHAIN_HEIGHT - current_height))
    
    # Calculate ETA
    avg_speed=$(calculate_average_speed)
    if [ $avg_speed -gt 0 ]; then
      # Convert back from precision multiplication and calculate seconds
      eta_seconds=$((blocks_remaining * 1000 / avg_speed))
      eta_formatted=$(format_duration $eta_seconds)
      
      # Check if we're within 15 minutes of completion
      if [ $eta_seconds -lt 900 ] && [ "$FIFTEEN_MIN_NOTIFIED" = "false" ]; then
        FIFTEEN_MIN_NOTIFIED=true
        send_slack_alert "â° **Prod** server reindexing is approximately 15 minutes from completion! Current: $(printf "%'d" $current_height), Target: $(printf "%'d" $CURRENT_CHAIN_HEIGHT)"
        echo "[$(date +'%Y-%m-%d %H:%M:%S')] MONITOR: 15-minute warning sent" >> "$LOG_FILE"
      fi
    else
      eta_formatted="calculating..."
    fi
    
    # Check for million milestones
    current_million=$((current_height / BLOCK_INTERVAL))
    
    if [ "$current_million" -gt "$LAST_MILLION_NOTIFIED" ] && [ "$current_million" -gt 0 ]; then
      LAST_MILLION_NOTIFIED=$current_million
      formatted_number=$(printf "%'d" $((current_million * BLOCK_INTERVAL)))
      progress_percent=$((current_height * 100 / CURRENT_CHAIN_HEIGHT))
      
      # Build notification with ETA - PRODUCTION
      notification="ğŸ¯ **Prod** server reindexing reached $formatted_number blocks ($current_million million)!"
      notification="$notification\nProgress: $progress_percent% ($(printf "%'d" $blocks_remaining) blocks remaining)"
      if [ "$eta_formatted" != "calculating..." ]; then
        blocks_per_sec=$((avg_speed / 1000))
        notification="$notification\nSpeed: ~$blocks_per_sec blocks/sec | ETA: $eta_formatted"
      fi
      
      send_slack_alert "$notification"
      echo "[$(date +'%Y-%m-%d %H:%M:%S')] MONITOR: Million milestone: $current_million million, ETA: $eta_formatted" >> "$LOG_FILE"
    fi
  fi
  
  # Check for catchup completion using docker logs
  logs=$(docker logs "$APP_NAME-$INACTIVE_ENV" 2>&1 | tail -n 300)
  count=$(echo "$logs" | grep -c 'catchup completed')
  echo "[$(date +'%Y-%m-%d %H:%M:%S')] MONITOR: Catchup completion messages: $count, Current height: $current_height" >> "$LOG_FILE"
  
  if [ "$count" -ge 1 ]; then
    echo "[$(date +'%Y-%m-%d %H:%M:%S')] MONITOR: Sufficient catchup logs detected. Switching traffic to $INACTIVE_ENV" >> "$LOG_FILE"
    
    # Send completion notification with highest seen block - PRODUCTION
    if [ $HIGHEST_SEEN_BLOCK -gt 0 ]; then
      formatted_final=$(printf "%'d" $HIGHEST_SEEN_BLOCK)
      send_slack_alert "âœ… **Prod** server reindexing completed at block $formatted_final! Switching traffic to $INACTIVE_ENV."
    else
      send_slack_alert "âœ… **Prod** server reindexing completed! Switching traffic to $INACTIVE_ENV."
    fi
    
    # Original traffic switching logic
    sed -i "s/server localhost:$ACTIVE_PORT;/# server localhost:$ACTIVE_PORT;/" "$NGINX_CONF"
    sed -i "s/# server localhost:$INACTIVE_PORT;/server localhost:$INACTIVE_PORT;/" "$NGINX_CONF"
    if nginx -t; then
      systemctl reload nginx
      echo "[$(date +'%Y-%m-%d %H:%M:%S')] MONITOR: Switched to $INACTIVE_ENV" >> "$LOG_FILE"
      exit 0
    else
      echo "[$(date +'%Y-%m-%d %H:%M:%S')] MONITOR: ERROR: Invalid NGINX config" >> "$LOG_FILE"
      send_slack_alert "âŒ **Prod** server: ERROR during traffic switch - invalid NGINX config"
      exit 1
    fi
  fi
  sleep 60
done
```

### nginx.conf
```nginx
nginx# Define rate limit zones
limit_req_zone $binary_remote_addr zone=api_limit:10m rate=30r/s;
upstream penumbra-explorer {
  # server localhost:8080;  # Blue environment
  server localhost:8081;  # Green environment
}
# New domain server block
server {
  server_name api.explorer.penumbra.zone;
  
  # Rate limiting configuration with proper error handling
  limit_req zone=api_limit burst=20 nodelay;
  limit_req_status 429;
  location = / {
    return 301 https://api.explorer.penumbra.zone/graphql/playground;
  }
  
  location / {
    proxy_pass http://penumbra-explorer;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # WebSocket support
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
    
    proxy_connect_timeout 300;
    proxy_send_timeout 300;
    proxy_read_timeout 300;
    send_timeout 300;
  }
  
  location /graphql {
    proxy_pass http://penumbra-explorer/graphql;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # WebSocket support
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
    
    proxy_connect_timeout 300;
    proxy_send_timeout 300;
    proxy_read_timeout 300;
    send_timeout 300;
  }
  
  location /graphql/playground {
    proxy_pass http://penumbra-explorer/graphql/playground;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    proxy_connect_timeout 300;
    proxy_send_timeout 300;
    proxy_read_timeout 300;
    send_timeout 300;
  }
  
  # Add WebSocket endpoint for GraphQL subscriptions
  location /graphql/ws {
    proxy_pass http://penumbra-explorer/graphql/ws;
    proxy_set_header Host $host;
    proxy_set_header X-Real-IP $remote_addr;
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Proto $scheme;
    
    # WebSocket support
    proxy_http_version 1.1;
    proxy_set_header Upgrade $http_upgrade;
    proxy_set_header Connection "upgrade";
    
    proxy_connect_timeout 300;
    proxy_send_timeout 300;
    proxy_read_timeout 300;
    send_timeout 300;
  }
  
  # Custom error page for rate limiting
  error_page 429 = @rate_limited;
  
  location @rate_limited {
    default_type application/json;
    return 429 '{"error":"Rate limit exceeded. Please try again later."}';
    add_header Retry-After 10;
  }
  listen 443 ssl; # managed by Certbot
  ssl_certificate /etc/letsencrypt/live/api.explorer.penumbra.zone/fullchain.pem; # managed by Certbot
  ssl_certificate_key /etc/letsencrypt/live/api.explorer.penumbra.zone/privkey.pem; # managed by Certbot
  include /etc/letsencrypt/options-ssl-nginx.conf; # managed by Certbot
  ssl_dhparam /etc/letsencrypt/ssl-dhparams.pem; # managed by Certbot
}
# HTTP redirect for new domain
server {
  if ($host = api.explorer.penumbra.zone) {
    return 301 https://$host$request_uri;
  } # managed by Certbot
  
  server_name api.explorer.penumbra.zone;
  listen 80;
  return 404; # managed by Certbot
}
```
# ğŸš€ Sprint 3 Review (20.06.2025)

## ğŸ“º Demo-Ablauf

- âœ… GitHub Projects Board zeigen (alle User Stories â†’ Done)
- âœ… Live Blue-Green Deployment Demo
- âœ… Slack-Integration in Action
- âœ… Zero-Downtime Beweis mit Load-Testing
- âœ… Architektur und Scripts erklÃ¤ren

---

## ğŸ—£ï¸ Feedback von Corrado

> [Platzhalter fÃ¼r Review-Notizen]

---

## ğŸ§¾ PrÃ¤sentierte Ergebnisse

- [Platzhalter fÃ¼r Demo-Details]  
- [Platzhalter fÃ¼r technische Highlights]

---

## ğŸ’¬ Feedback

- [Platzhalter fÃ¼r Corrados Feedback]  
- [Platzhalter fÃ¼r Action Items]

---

## ğŸ¤ Vereinbarte Punkte

- [Platzhalter fÃ¼r Follow-up Actions]  
- [Platzhalter fÃ¼r finale Dokumentation]

---

## âœï¸ Mein Sprint 3 Fazit

Sprint 3 war der **HÃ¶hepunkt des Projekts!** Das Blue-Green System funktioniert **genau wie geplant**:

- âœ… **Zero-Downtime Deployments** â€“ Mission accomplished!
- âœ… **Vollautomatisch** â€“ Von GitHub Release bis Production Switch
- âœ… **Monitoring & Alerting** â€“ Team wird Ã¼ber Slack informiert
- âœ… **Production-tested** â€“ Mehrere erfolgreiche Deployments gelaufen

### âœ… Bottom Line:
Das **Penumbra Explorer Backend** kann jetzt **ohne jegliche Downtime geupdatet** werden.  

### Sprint 3 Retrospektive

![Sprint 3 Retrospektive](docs/images/sprint3retrospective.png)
*Sprint 3 Retrospektive - Blue-Green Deployment und Zero-Downtime Achievement*

![Sprint 3 Ende](docs/images/endesprint3.png)
*Sprint 3 erfolgreich abgeschlossen - Blue-Green Deployment System ist live!*

## Fazit

### Meine erste Semesterarbeit an der TBZ

Obwohl dies die Semesterarbeit des 3. Semesters ist, war es tatsÃ¤chlich meine erste Semesterarbeit an der TBZ, da ich direkt ins 3. Semester eingestiegen bin. Diese besondere Ausgangslage machte das Projekt zu einer noch intensiveren Lernerfahrung fÃ¼r mich.

### Ein Projekt mit echtem Impact

Was diese Semesterarbeit fÃ¼r mich so wertvoll machte, war die Kombination aus theoretischem Lernen und praktischer Anwendung. Ich konnte nicht nur neue Technologien und Konzepte erlernen, sondern diese direkt in einem produktiven Umfeld bei meinem Arbeitgeber PK Labs einsetzen. Das Resultat â€“ ein vollstÃ¤ndiges Zero-Downtime Deployment-System â€“ lÃ¶st ein reales Problem und wird aktiv genutzt.

### Die Bedeutung von gutem Mentoring

Ein besonderer Dank gilt Corrado Parisi fÃ¼r die drei Sprint Review Meetings. Jedes Mal erhielt ich konstruktives und durchdachtes Feedback, mit dem ich konkret weiterarbeiten konnte. Diese regelmÃ¤ssigen Touchpoints halfen mir, auf Kurs zu bleiben und kontinuierlich zu lernen. Die agile Arbeitsweise mit Scrum, angepasst auf ein Einzelprojekt, erwies sich als ideales Framework fÃ¼r diese Arbeit.

### Win-Win-Win Situation

Am Ende dieses Projekts kann ich mit Stolz sagen, dass alle Beteiligten profitiert haben:

- **Ich selbst** habe enorm viel gelernt â€“ von Blue-Green Deployment-Patterns Ã¼ber Bash-Scripting bis hin zu Production-Ready Infrastructure
- **PK Labs** erhielt eine robuste Deployment-LÃ¶sung, die von 832 Stunden Downtime pro Jahr auf 0 reduziert
- **Die Dozenten** (so hoffe ich) hatten Freude daran, ein praxisnahes Projekt zu begleiten und zu bewerten

### PersÃ¶nliche Reflexion

Diese Semesterarbeit hat mir gezeigt, wie bereichernd es ist, wenn Ausbildung und Berufspraxis Hand in Hand gehen. Die Herausforderungen waren real, die LÃ¶sungen mussten production-ready sein, und das Feedback war stets konstruktiv. 

Ich hoffe, dass meine Begeisterung fÃ¼r dieses Projekt in der Dokumentation und PrÃ¤sentation spÃ¼rbar ist. Es war nicht nur eine Pflichtaufgabe, sondern ein Projekt, in das ich mit Leidenschaft investiert habe.

### Abschliessende Worte

Mit diesem Projekt habe ich bewiesen, dass Zero-Downtime nicht nur ein Buzzword ist, sondern eine erreichbare RealitÃ¤t. Wenn alle Parteien â€“ Student, Unternehmen und Bildungsinstitution â€“ zusammenarbeiten, entstehen LÃ¶sungen, die einen echten Mehrwert schaffen.

**Mission Accomplished: Von 34.6 Tagen Downtime auf 0. FÃ¼r immer.**
---
<p align="left">
  <img src="docs/images/pklabs_logo.png" alt="PK Labs Logo">
</p>
*Dieses Projekt wird im Rahmen der TBZ Semesterarbeit fÃ¼r PK Labs umgesetzt.*

*Letzte Aktualisierung: 19.06.2025*
